{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Probability of Missing Weights\n",
    "\n",
    "## Single Missing Variable\n",
    "\n",
    "This tutorial describes inverse probability of missing weights (IPMW) for a single missing variable. I will describe the general usage of IPMW, broadly how it works, and demonstrate their usage within *zEpid*. This example focuses on a single missing variable\n",
    "\n",
    "In the following example, we will use a simulated data set that comes with *zEpid*. For the example, our question of interest is the proportion of those died in our sample by week 45. First we will load the data and look at the variable ``dead``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import zepid\n",
    "from zepid import load_sample_data\n",
    "from zepid.causal.ipw import IPMW\n",
    "\n",
    "print(zepid.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 547 entries, 0 to 546\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      547 non-null    int64  \n",
      " 1   male    547 non-null    int64  \n",
      " 2   age0    547 non-null    int64  \n",
      " 3   cd40    547 non-null    int64  \n",
      " 4   dvl0    547 non-null    int64  \n",
      " 5   art     547 non-null    int64  \n",
      " 6   dead    517 non-null    float64\n",
      " 7   t       547 non-null    float64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 38.5 KB\n"
     ]
    }
   ],
   "source": [
    "df = load_sample_data(timevary=False).drop(columns=['cd4_wk45'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output we can see that 30 individuals in the sample are missing the variable ``dead``. From here we can proceed under two different assumptions; 1) assume that ``dead`` is missing completely at random, or 2) assume that ``dead`` is missing at random.\n",
    "\n",
    "*Note*: this example uses survival data, where an approach that allows for censoring (i.e. Kaplan-Meier estimator) is a better approach. For the sake of the example, we will imagine that we don't have survival times (i.e. ``t`` is not included in our data set)\n",
    "\n",
    "### 1) Missing Completely at Random\n",
    "The assumption of missing completely at random (MCAR) means that the missingness of ``dead`` is unrelated to any other variable. Under this assumption, the mean in the observed data is an acceptable replacement for the mean in the data *if we had observed* ``dead`` for all 547 individuals. We can use the standard probability estimator\n",
    "\n",
    "$$\\widehat{\\Pr}(Y) = \\frac{\\sum_{i=1}^n I(Y_i=1)}{n}$$\n",
    "\n",
    "which is a consistent estimator under MCAR (meaning that as the sample size goes to infinity, the estimate converges to the truth). In the above equation, $I(.)$ is the indicator function, where it takes a value of $1$ when true. We can easily implement this estimator by taking the mean of ``dead`` with ``numpy.mean``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Mean: 0.168\n"
     ]
    }
   ],
   "source": [
    "# Proportion dead at t=45 assuming dead is Missing Completely at Random\n",
    "print('MCAR Mean:', np.round(np.mean(df['dead']), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the observed data, 16.8% of individuals died by week 45, under the assumption that ``dead`` is missing completely at random.\n",
    "\n",
    "MCAR is a strong assumption, that is often unlikely to be true when missing data occurs. We can make a less restrictive assumption. More specifically, we can assume that missing ``dead`` are random conditional on some set of covariates. This is referred to as missing at random (MAR) in the missing data literature\n",
    "\n",
    "### 2) Missing at Random\n",
    "Under this assumption, the missingness of ``dead`` is dependent on some known set of variables. To account for the variables related to missingness, we will use IPMW (there are other approaches). First, let's introduce the mathematical notation to calculate IPMW. For individual $i$, their weight is\n",
    "\n",
    "$$w_i = \\frac{1}{\\Pr(M_i=1 | L_i)}$$\n",
    "\n",
    "where the denominator is the probability of observing ($M$) individual $i$ given their covariates $L$. With the addition of IPMW, our estimator becomes\n",
    "\n",
    "$$\\widehat{\\Pr_w}(Y) = \\frac{\\sum_{i=1}^n I(Y_i=1)*w_i}{\\sum_{i=1}^n w_i}$$\n",
    "\n",
    "In *zEpid*, inverse probability of missing weights can be calculated using the ``IPMW`` class. \n",
    "\n",
    "The first step is to initialize the IPMW class. We will give the class the following; the data set (``df``), the variable that has missing data (``dead``), and specify that we want the stabilized weights.\n",
    "\n",
    "Following that, we will specify the regression model we want to use. In the above functions, this refers to $L$. We will make the assumption that ``dead`` is missing at random with the following variables; age (``age0`` modeled with a quadratic term), CD4 T cell count (``cd40`` modeled with a quadratic and cubic term), antiretroviral therapy (``art`` binary), and gender (``male`` binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "Propensity Score Model\n",
      "                  Generalized Linear Model Regression Results                   \n",
      "================================================================================\n",
      "Dep. Variable:     _observed_indicator_   No. Observations:                  547\n",
      "Model:                              GLM   Df Residuals:                      539\n",
      "Model Family:                  Binomial   Df Model:                            7\n",
      "Link Function:                    logit   Scale:                          1.0000\n",
      "Method:                            IRLS   Log-Likelihood:                -110.74\n",
      "Date:                  Wed, 30 Dec 2020   Deviance:                       221.48\n",
      "Time:                          10:49:10   Pearson chi2:                     548.\n",
      "No. Iterations:                       6                                         \n",
      "Covariance Type:              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.6060      2.473      0.245      0.806      -4.241       5.453\n",
      "art            0.9588      0.762      1.258      0.208      -0.535       2.452\n",
      "male          -0.1756      0.512     -0.343      0.732      -1.180       0.829\n",
      "age0           0.0262      0.131      0.200      0.842      -0.231       0.283\n",
      "age_sq        -0.0001      0.002     -0.066      0.948      -0.004       0.003\n",
      "cd40           0.0262      0.012      2.211      0.027       0.003       0.049\n",
      "cd4_sq     -9.906e-05   5.96e-05     -1.661      0.097      -0.000    1.78e-05\n",
      "cd4_cu       1.06e-07    7.9e-08      1.342      0.180   -4.88e-08    2.61e-07\n",
      "==============================================================================\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Creating functional form variables\n",
    "df['age_sq'] = df['age0']**2\n",
    "df['cd4_sq'] = df['cd40']**2\n",
    "df['cd4_cu'] = df['cd40']**3\n",
    "\n",
    "# Calculating IPMW\n",
    "ipm = IPMW(df, missing_variable='dead', stabilized=False)\n",
    "ipm.regression_models(model_denominator='art + male + age0 + age_sq + cd40 + cd4_sq + cd4_cu', \n",
    "                     print_results=True)\n",
    "ipm.fit()  # Calculates the weights after the regression models are fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output to the console provides the logistic regression models betas and fit statistics. These can be suppressed by setting ``print_results=False``\n",
    "\n",
    "From the ``IPMW`` class, we can now extract out the calculated IPMW for each individual and add them to our data set. We can do that with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAR Mean: 0.17\n"
     ]
    }
   ],
   "source": [
    "# adding weights into the original data set\n",
    "df['w'] = ipm.Weight\n",
    "\n",
    "# Calculating the weighted proportion of dead\n",
    "print('MAR Mean:', np.round(np.sum(df['dead']*df['w']) / np.sum(df['w']), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By week 45, 17.0% of individuals died, assuming that ``dead`` is missing at random, conditional on age, gender, ART status, and CD4 count. While the results between the examples are not too different, in practice they might be divergent. The missing at random is a weaker assumption than missing completely at random.\n",
    "\n",
    "Stabilized IPMW is also an option. Below is code to calculate the proportion of deaths with stabilized weights instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAR Mean: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Calculating IPMW\n",
    "ipm = IPMW(df, missing_variable='dead', stabilized=True)\n",
    "ipm.regression_models(model_denominator='art + male + age0 + age_sq + cd40 + cd4_sq + cd4_cu', \n",
    "                     print_results=False)\n",
    "ipm.fit()  # Calculates the weights after the regression models are fit\n",
    "\n",
    "# adding weights into the original data set\n",
    "df['sw'] = ipm.Weight\n",
    "\n",
    "# Calculating the weighted proportion of dead\n",
    "print('MAR Mean:', np.round(np.sum(df['dead']*df['sw']) / np.sum(df['sw']), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "I have briefly went over assumptions regarding missing data, what IPMW are, and how to use them with *zEpid*. While presented in the simple case where we wanted a single mean, these weights are also valuable when used in conjunction with other inverse probability weights in analyses. Additionally, these weights are one way to deal with missing data under the missing at random assumption. Please view other tutorials for more information on functions in *zEpid*\n",
    "\n",
    "#### Further Readings\n",
    "Sun, B., Perkins, N. J., Cole, S. R., Harel, O., Mitchell, E. M., Schisterman, E. F., & Tchetgen Tchetgen, E. J. (2017). Inverse-probability-weighted estimation for monotone and nonmonotone missing data. American Journal of Epidemiology, 187(3), 585-591.\n",
    "\n",
    "Perkins, N. J., Cole, S. R., Harel, O., Tchetgen Tchetgen, E. J., Sun, B., Mitchell, E. M., & Schisterman, E. F. (2017). Principled approaches to missing data in epidemiologic studies. American Journal of Epidemiology, 187(3), 568-575.\n",
    "\n",
    "Li, L., Shen, C., Li, X., & Robins, J. M. (2013). On weighting approaches for missing data. Statistical Methods in Medical Research, 22(1), 14-30.\n",
    "\n",
    "Greenland, S., & Finkle, W. D. (1995). A critical look at methods for handling missing covariates in epidemiologic regression analyses. American journal of epidemiology, 142(12), 1255-1264.\n",
    "\n",
    "Seaman, S. R., & White, I. R. (2013). Review of inverse probability weighting for dealing with missing data. Statistical Methods in Medical Research, 22(3), 278-295."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
